#Controlling the HaSAPPy workflow with command scripts


The HaSAPPy analysis pipeline is controlled by a command script that is provided by the user (the LoadModule.txt file). All the parameters are collected by the **INFOloads.py** module and stored in an **INFO object** that organizes software scheduling and stores user defined parameters.
The file is subdivided in different sections marked by an identification number (0-9); each section is characterized by multiple input fields that are marked with a TAG `@1a)`, consisting of an `@`, the section number, a letter referring to the specific input field, and a `)`, after which user input can be entered on the same line:
```
@1A) <Operator name>
```

> **NOTE:** Avoid modifing the TAG, otherwise **INFOloads.py** will not parse the file correctly and fail to load parameters. Spaces between the TAG and the input are acceptable, but will not be accepted for PATH names.

This tutorial explains all sections of a HaSAPPy command script and illustrates the use of parameters to specify the workflow.
For this purpose, it will be assumed that all files are under a HaSAPPy folder within the user home directors, abbreviated as:

```
Users/User
```

A HaSAPPy command script is separated into 9 sections corresponding to the steps of data processing, analysis, and output customization.

## Section 0: Which analysis would you like to perform?

Select which step of the analysis to perform. Mark ‘Y’ to execute the corresponding step of the pipeline, 'N' else.

```
Trim adaptor and sequence quality selection     (fill up section 2):
@0A)n

Alignment and discharging Phix genome           (fill up section 3):
@0B)N	
Alignment to reference genome                   (fill up section 4):
@0C) y

Identification of Independent Insertions (I.I.) (fill up section 5):
@0D)    Y
Classification of I.I. in genes			         (fill up section 6):
@0E) Y

Comparison of different experiments 		     (fill up section 7):
@0F) Y

Generate Tables summarising analysis results 	  (fill up section 8):
@0G)Y

Visualise insertions by genes representation 	  (fill up section 9):
@0H) N
```

Spcifying a `y` or `Y` after a TAG will include the specified process into the data analysis workflow. `N` or `n` prevents the step from being scheduled. Note: Some steps depend on output of other modules and it is the user's responsibility to ensure that dependencies are met by scheduling consecutive processing steps.

> **IMPORTANT:** HaSAPPy will ignore any information in sections that were excluded from scheduling including any errors.

In the pipeline multiple modules can be processed if they are performed in succession: the following module needs information generated by the previous one during the analysis and these information can not be provided by the user (Alignment and discharging PhiX genome is an exception).

## Section 1: General Information

A user name can be provided that will be recorded along with the run information (this field is optional):

```
Operator Name: 
@1A) Anton Wutz
```

The folder for all files produced by an analysis workflow can be specified through a user selected PATH in the filesystem. The PATH must exist in the file system and point to the top-level folder where the folder structure for HaSAPPy intermedidiary and output files will be stored. It is the responsibility of the user to ensure that enough storage capacity is available to store the entire set of data files, which can be significant depending on the scale of the project:

```
Storing location (provide a correct path):
@1B) /Users/User/HaSAPPy/experiments
```

The **INFOloads.py** module will generate the following folder structure for the analysis:

```
/Users/User/HaSAPPy/experiments/
│
├── *library*_yyyy-mm-dd
│   │
│   ├── graph
│   │   └── <graphic output of run>
│   └── raw
│       └── <intermediary files of data processing>
│
└── Analysis
│
├── yyyy-mm-dd_info.txt
│
├── graph
│   └── <graphic output when specified>
└── raw
└── <data bases>
```

For each NGS read dataset analyzed a specific folder will be generated using as reference the library name provided by the user in the following section. If a similar folder already exists, HaSAPPy will request an alternative name for library name/destination. Output files from section 1 to section 6 will be written to this folder. The library_info.txt file records all information of the run and of the selected parameters.

Information and data obtained from section 7 to 9 are not referring to a particular library but instead to an analysis performed comparing multiple libraries. Data will be collected in the Analysis folder according to the date in which the analysis is performed. If a similar folder already exists, HaSAPPy will request an alternative name for analysis destination.


## Section 2: Read trimming of adaptor and and low quality sequences

```
How many libraries do you want to analyse?:
@2A) 2
Are those libraries sequenced pair-end?:
@2B) N
```

The name of the library will be used as first attempt as name for folder generation and will be used as `tag` to generate file names of output and table headers for Group analysis. It is requested that the user selects a short and meaningful name that must not contain spaces:

> **IMPORTANT** Don’t use spaces in the name!!

```
Name of the libraries (add additional lines if necessary):
@2C) Exp1
@2C) Exp2
…
```

Specify the absolute PATH (from the system root `/`) to the NGS read files in FastQ format. It is important to specify the file paths in the same order as the corresponding names of the experiments in `@2C)`. Compressed files (`.fastq.gz`) can also be processed:
```
Location of input file 1 (add additional lines if necessary):
@2D) /Users/User/HaSAPPy/experiments/raw_data/file1.fastq
@2D) /Users/User/HaSAPPy/experiments/raw_data/file2.fastq
…
```

If **paired-end sequencing** is used alignment of read pairs should be performed. For this a reverse read sequence fastq file can be provided containing the second sequencing run.
> **IMPORTANT:** The order of file names must be the same as in  `@2C)` and the forward read sequence in `@2D)` to ensure that HaSAPPy matches the correct read pairs and experiments:

```
Location of input file 2 (if paired-end) (add additional lines if necessary):
@2E)
@2E)
…
```

PCR amplification can lead to reads of a reduced length and consequently the NGS sequencing run might overlap the adaptor sequence on the other side. Provide the adaptor sequence that could be present at the end of the read for removal (on Illumina Sequencers the first sequence run can overlap the p7 adaptor and the second the p5 adaptor):
```
Adaptor p7 sequence (for trimming 3’ ends of sequence in file 1):
@2F) ATCTCGTATGCCGTCTTCTGCTT
Adaptor p5 sequence (for trimming 3’ ends of sequence in file 2):
@2G)
```

Base quality is reported in the FastQ read file. To eliminate low quality sequences from reads PreprocessReads scans the read for low quality bases that fall below a threshold for `Initial bad quality QA value detected ‘@2H)’`. If the remainder of the read has an average base quality below a `Quality average limit of 3’end sequence ‘@2J)’`, trimming of the read at this position is performed leaving a shorter read of good base quality. If the remainder of the read has sufficiently high average base quality, a low quality position is tolerated and scanning of the remainder of the read proceeds. This ensures that a maximum of sequencing data is retained for data analysis but bad quality reads are eliminated. Reads that become too short after trimming are also discarded, whereby a threshold of 26 bases is used to select reads.
```
Quality selection parameters:
Initial bad quality QA value detected:
@2H)  20
Quality average limit of 3’end sequence after the call of a bad quality base:
@2J) 25
```

Intermediate files of data processing can take up a lot of storage space. HaSAPPy has an option to retain all files or to delete the files once they are no longer needed. Enter `N` in the following input field, if you don’t want the permanently store the output file generated. In this case the file will be used by the Align module and erased thereafter.
```
Would you like to store quality selected libraries (mark ‘Y’ or ’N’)?
@2K) N
```

## Section 3: Alignment and discharging PhiX genome reads

If NGS sequence libraries were spiked with PhiX control fragments removal of the corresponding PhiX reads is required. Provide the absolute PATH to the Phix genome index for Bowtie2. The file name of the index without file extension should be provided (see Bowtie2 reference):
```
Location of Phix reference genome:
@3A) /Users/User/HaSAPPy/reference/Phix/NCBI/1993-04-28/Sequence/BowtieIndex/genome
```

Mark `N` if you don’t want the permanently store of the output read file that is generated. In this case the file will be used by the Align module and erased afterwards:
```
Would you like to store permanently Phix-cleaned files  (mark ‘Y’ or ’N’)?
@3B)
```

HaSAPPy provides the flexibility to start an analysis workflow with preprocessed read files in FastQ format. This facilitates the use of any tools for adaptor trimming. In this case, provide the FastQ files as the starting point of the analysis. Enter the name, read information, and absolute PATH of the Fastq files (the Fastq file must be decompressed):

> **NOTE:** HaSAPPy does not accept compressed FastQ files at this entry into the workflow!

```
!!!N.B. Compile the following section just if this is your starting point!!!
How many libraries do you want to analyse?:
@3C)
Are those libraries sequenced pair-end?:
@3D)	
Name of the libraries (add additional lines if necessary):
@3E)
@3E)
…
Location of input file 1(add additional lines if necessary):
@3F)
@3F)
…
Location of input file 2 (if pair-end) (add additional lines if necessary):
@3G)
@3G)
…
```

## Section 4: Alignment to the reference genome

For mapping reads to the reference genome (mouse or human, etc) HaSAPPy comes preconfigured for use of Bowtie2, NextGenMap (ngm), and nvBowtie. Enter the read alignment program you want to use for read mapping to the reference genome.
```
Alignment program to be used (bowtie2, nvBowtie, NextGenMap):
@4A) bowtie2
```
>**NOTE:** The selected read aligner must be installed on your system and reachable form the PATH.

Provide the absolute PATH of reference genome index for the selected read mapper. For bowtie2 and nvBowtie the path and file name of the genome index without file extension must be entered. For NextGenMap, provide the path to the genome sequence Fasta file (“xxxxx.fa” file):
```
Location of reference genome:
@4B) /Users/User/HaSAPPy/reference/Mus_musculus/UCSC/mm10/Sequence/BowtieIndex/genome
```

Enter `N` in the input field below, if you don’t want to permanently store the output file generated. In this case the file will be used by the IIdefinition module and erased afterwards:
```
Would you like to store permanently BAM aligned files  (mark ‘Y’ or ’N’)?
@4C)Y
```

If this is the first step in your workflow and this module is the starting point of the analysis, you should provide information on the name and properties of the NGS libraries and the corresponding Fastq files in the input fields below. This is particularly useful if tools from Illumina have been used for PhiX removal and adaptor trimming. It is possible to use preprocessed read files and specifying the Fastq files here.

> **NOTE:** If analysis starts here the Fastq file must be decompressed, HaSAPPy presently does not accept compressed formats at this step of the analysis.

```
!!!N.B. Compile the following section just if this is your starting point!!!
How many libraries do you want to analyse?:
@4D)	
Are those libraries sequenced pair-end?:
@4E)	
Name of the library (add additional lines if necessary):
@4F)
@4F)
…
Location of input file 1(add additional lines if necessary):
@4G)
@4G)
…
Location of input file 2 (if pair-end) (add additional lines if necessary):
@4H)
@4H)
…
```

## Section 5: Identification of Independent Insertions (I.I.)

For the definition of Independent Insertions from read files, a minimal number of read count can be provided. Insertions that have less than this threshold number of reads at positions will be discarded. This parameter can be useful for reducing noise deriving from sequencing procedure or contaminations. In case sequencing depth is not very deep it also could negatively affect library complexity and resolution (particularly in unselected control samples with large numbers of different insertions). An integer number should be provided. The default value is set at 1, which maintains all insertions.
```
Number of reads to define a I.I.:
@5A) 2
```

HaSAPPy provides the possibility to remove PCR-duplicates from the read count if libraries were sequenced in the paired-end mode. Reads that have exactly the same genomic alignment position on both ends will be merged as PCR duplicates. If you activate this option duplicates and not paired-ends aligned reads will be discharged.

> **NOTE:** This option is implemented in HaSAPPy as an experimental feature and will undergo further development as paired-end sequencing dataset for screening experiments become available.

```
If pair-end libraries, do you want to remove PCR-duplicates (mark ‘Y’ or ’N’)?
@5B) N
```

Read mappers provide information on the quality of reproted read alignments to the reference genome. This alignment quality parameter (MAPQ) takes the number of mismatches and matches as well as the uniqueness of the alignment position into account. Reads that have multiple potential mapping positions in the reference genome will have lower alignment quality values (see the documentation of the read mappers for details on the composition of this value). Increasing the alignment quality parameter can help to reduce alignment errors that could affect the analysis, but also will lead to the elimination of reads and therefore could lead to reduced sensitivity. Enter `Y` in the input field below, if you want to activate this selection and provide an integer number as MAPQ threshold (default is 0, all reported alignments are accepted):

```
Do you want to indicate a level of alignment fidelity (mark ‘Y’ or ’N’):
@5C) Y
If level of alignment fidelity is requested, provide a limit number:
@5D) 5
```

HaSAPPy provides the possibility to enter a workflow at this step. If this module is the starting point of your analysis, you should supply information on the name and properties of the NGS libraries and the paths to the read alignment files in SAM format:

> **NOTE:** HaSAPPy does not yet accept BAM files as input at this step in the workflow and SAM format has to be used. This avoids repeated compression and decompression, which decreases processing demand but adds to storage requirements.

```
!!!N.B. Compile the following section just if this is your starting point!!!
How many library do you want to analyse?:
@5E)	
Are those libraries sequenced pair-end?:
@5F)	
Name of the library (add additional lines if necessary):
@5G)
@5G)
…
Location of input file 1(add additional lines if necessary):
@5H)
@5H)
…
```

## Section 6: Classification of I.I. in genes

To categorize I.I. according their location in genes, you are requested to provide the gene reference file created with the **GeneReference_built.py** module. The absolute PATH and file name including extension must be entered:

>**IMPORTANT;** Specify a gene annotation reference that has been generated from the **same genome assembly** that has been used as the reference genome for mapping the NGS reads!!!

```
Location of gene reference:
@6A) Users/User/HaSAPPy/docs/GeneReference_Mouse-MM10.pkl
```

User can define which parameters should be collected during this process. Mark ‘Y’ or ‘N’ according to your needs. For details on parameter description refer to the HaSAPPy manual.
> **IMPORTANT** Parameters that are not selected with `Y`, will not be stored and will not be available for the following steps of the workflow.

```
Type of parameters analysed (mark ‘Y’ or ’N’):
Independent insertions (I.I.):
@6B) Y
Killing insertions (K.I.):
@6C) Y
Bias insertions:
@6D) Y
Reads:
@6E) N
```

If this module is the starting point of the analysis, you should provide information on the name and properties of the libraries and the `../../*library*_dddd-mm-yy/raw/*library*.IIRawData.pkl` database generated by a previous workflow through the **IIDefinition.py** module.
```
!!!N.B. Compile the following section just if this is your starting point!!!
How many library do you want to analyse?:
@6F)	
Are those libraries sequenced pair-end?:
@6G)	
Name of the library (add additional lines if necessary):
@6H)
@6H)
…
Location of input file 1(add additional lines if necessary):
@6I)
@6I)
…
```

## Section 7: Comparison of different experiments

The **GroupAnalysis.py** module uses input data that was generated by the **GeneDefinition.py** module for each NGS library. Individual NGS datasets are associated with experiments. One reference (control) and multiple selected groups can be specified. This could for example be useful if a time-course screening is performed and selection would be followed by drawing sampled from sequential timepoints. A simple experiment would just have an unselected and a selected group, which each contain several NGS datasets of the replicates. For this reason the minimum number of this comparison is 2 groups.

All previously calculated parameters (II,KI,Bias,bias_FW,bias_RV,Reads) can be selected for a group analysis. Calculation of the mean and standard deviation for a group from the replicates is supported. Experimental groups are also compared to the reference group and fold difference, ttest, and Outlier analysis are calculated.

Provide the number of groups present in your analysis. An integer number >= 2 is requested 
```
Number of groups to be analysed:
@7A) 3
```

The name of the reference group must be provided. This name will be used in table column headings. For the reference group mean and standard deviation will be calculated BUT fold difference, ttest, etc will not be available for this group (these parameters are provided only for experimental groups as this is the reference for the comparison). In general, unselected libraries are used as reference.
```
Reference group name:
@7B) Unselected
```

Provide the names of the NGS libraries present in the group. A list of library names subdivided by a `,` is requested. Spaces between library names are accepted and trimmed by HaSAPPy. If this is not the starting point of the analysis, libraries name must correspond to the library names defined in the previous section `@2C)` modules.
> New libraries produced in previous runs of the workflow cannot be added at this stage into the pipeline. If you need to combine NGS datasets from multiple data processing runs at this stage, a new pipeline can be generated starting from the GroupAnalysis.py module in which all NGS libraries used for the analysis can be introduced in the ‘starting point’ tasks (see below) of this section.

```
Reference group data (provide the library names separated by a ‘,’ (ex. ‘lib1,lib2,lib3’)):
@7C) ctrl1 ,ctrl2, ctrl3
```

Provide the name of the analysed group. If you have several experimental conditions (eg timepoints in selection), multiple groups can be created. They will all be compared to the reference group. For each experimental group a line starting with an `@7D)` TAG followed by the group name should be added:
```
Other data group name(add additional lines if necessary):
@7D) Condition_A
@7D) Condition_B
…
```

As for the reference group, provide the names for the NGS libraries corresponding to the replicates of the groups.

>**IMPORTANT: ** HaSAPPy requires one line for each list of NGS library names. The order of the lines must be exactly the same as the names of the groups are provided in `@7D)`.

```
Other data group (provide the library names separated by a ‘,’ (ex. ‘lib1,lib2,lib3’))(add additional lines if necessary):
@7E) ExpA_1, ExpA_2, ExpA_3
@7E) ExpB_1, ExpB_2, ExpB_3
…
```

Selection of parameters that should be calculated requires a simple `Y` or `N` in the following input fields. If a parameter was not calculated during data processing by **GeneDefinition.py module**, this parameter is automatically be skipped from the following analysis.

> **NOTE:** If you are comparing libraries with a different set of analysed parameters (only valid if this is the starting point of your analysis), HaSAPPy can terminate with an error. In this case, please check that all parameters analysed are logged in the library_info.txt file for the different libraries. To avoid this problem entirely it is recommended to calculate all parameters during data processing in the workflow.

```
Type of parameters analysed (mark ‘Y’ or ’N’):
Independent insertions (I.I.):
@7F) Y
Killing insertions (K.I.):
@7G) Y
Bias insertions:
@7H) Y
Reads:
@7I) N
```

To summaries the results of multiple parameters and to provide a ranking of the most promising candidates, genes can be sorted by an outlier test (for details on the Outlier analysis refer to HaSAPPy manual). Entering `Y` in the input field below activates this feature and the outlier factor will be available for further steps of the analysis (eg include in output tables, and 3D parameter distribution plots).
```
Perform Outlier analysis(mark ‘Y’ or ’N’):
@7J) Y
```

Among the parameters selected for the GroupAnalyis, you can mark those one that you want to use for derivation of the Outlier value. These input fields are only required if the Outlier option was activated:
```
Parameters used for Outlier analysis (Fill this part just if marked ‘Y’ to the previously task):
Type of parameters analysed (mark ‘Y’ or ’N’):
Independent insertions (I.I.):
@7K) Y
Killing insertions (K.I.):
@7L) Y
Bias insertions:
@7M) Y
Reads:
@7N) N
```

Outlier analysis is performed for comparison of the ratio of specified parameters between the analysed experimental group and the reference group. A Fold value does not contain information on the absolute number of insertions observed for a gene in the experiment. Therefore, it could happen that genes with very few or no insertions in the reference group would reach a high Outlier value (underrepresentation in the reference group is not uncommon due to undersampling). For correcting for this behavior a Confidence value can be specified as a percentage (0-100) with which the absolute number of insertions will be used to correct the outlier outcome for the gene (a recommened starting fidelity value is 10). An integer number between 0 to 100 is required:
```
Confidence value for Outlier analysis(Fill this part just if marked ‘Y’ to the 7J task):
Provide a value between 0 to 100 (ex. 10)
@7O) 10
```

If this module is the **starting point of the analysis**, you should provide information on the name and locations of the database files for the NGS libraries ( “../../library_dddd-mm-yy/raw/library.GenesData.pkl”) generated by the **GeneDefinition.py** module. One line is added for each library. Pay attention to the name correspondence with the one used in section `@7C)` and `@7E)`:
```
!!!N.B. Compile the following section just if this is your starting point!!!
How many library do you want to analyse?:
@7P)	
@7P)
…	
Name of the library (Use the same names provided in section 7C and 7E) (add additional lines if necessary):
@7Q)	
@7Q)
…
Location of input file (add additional lines if necessary):
@7R)	
@7R)
…
```

## Section 8: Generate tables

The **Tables.py** module implements the output section of the workflow for generating a summary of all calculated parameters on the datasets in table format. Multiple tables can be specified and will be combined into an .xlsx formated file that can be opened by common spreadsheet programs (eg. LibreOffice Calc, Microsoft Excel, or WPS (Kingsoft) Office Spreadsheet). The parameters to be included and the layout of the tables can be customized in the command script. In addition, criteria for  sorting and filtering the data can be specified.

Specify the names for the tables (Excel sheets) that you want to generate. Each worksheet name should be entered on a separate line (multiple worksheets can be generated):
```
Table name representation(add additional lines if necessary):
@8A) All_data
@8A) mean
@8A) Fold+stdev
@8A) Score
… 
```

The **Table.py** module collects user information for 3 parameters:

1. Samples - Which group you want to represent: If you selects ‘all’, all the group will be represented (following our example: Unselected, Condition_A, Condition_B). If instead you are providing a specific group name (eg. Condition_A), pay attention to use the group name that was provided in section 7.
2. Parameters - Which parameter you want to represent for the selected groups: choose from II, KI, Bias, bias_FW, bias_RV, Reads and Score (Outlier analysis). If you enter ‘all’, all available parameters for the indicated group will be presented in the output table.
3. Data type - Which information of the selected parameter should be included in the table; choose between:
* ‘raw’: provides parameter values for all individual replicates of the selected groups (each as a column in the table)
* ‘mean’: provides parameter values of the average of the replicates of the selected groups (one column per group)
* ‘stdev’,’fold’ and ’ttest’: provides parameter information of the comparison of the analysed group respect to the reference. These are skipped from the analysis for the reference group (eg unselected or control group)

Entering ‘all’ for any of the parameters will include all possible combinations of the data types for this parameter in the output table. The Score parameter doesn’t take any Data type information.

Using these 3 elements you can generate a selector and design your table format. The selector structure to provide is:
```
(Samples, Parameters, Data type)
```
In a table you can provide multiple selecting criteria adding selectors marked with a ‘,’:
```
(Samples_1, Parameters_1, Data type_1) , (Samples_2, Parameters_1, Data type_2)
```
```
Construct table representation using following keys (each new line correspond to a table):
!!!Read Info file to have detailed informations of how to compile this part!!!
Samples: all, group name
Parameters: all, II, KI, Bias, bias_FW, bias_RV, Reads, Score (N.B. Score parameter doesn’t need any 'Data type')
Data type: all, raw, mean, stdev, fold, ttest
ex. :  	(all,II,raw),(group1,KI,mean)
(group1,KI,ttest),(all,Score)
@8B)(all,all,all)
@8B)(all,all,mean)
@8B)(all,all,fold),(all,all,stdev)
@8B)(all,Score)
…
```

The user can also filter and sort the data in the output tables.
Filter definition depends on 3 elements:

1. Keys: A selector of a parameter as defined in the previous input field. Only unique identifiers are permitted and the ‘all’ selector is not supported. The key does not need to be actually present in the generated table, but can refer to any selector available in the analysis
2. Symbols: available symbols can come from comparators: ‘>’, ‘>=’, ‘<’ , ‘<=’ , ‘==’, or indicate ordering: ‘ascending’, ‘descending’
3. Number: if as comparator symbol was used, a number must follow for naking the comparison.

Using these 3 elements you can generate a filter and design your table format. The selector structure to provide is:
```
filter[Keys ,symbols,number]
```
In a table you can provide multiple criteria for seletion by adding multiple filters separeted by a comma (`,`):
```
filter[Keys_1 ,symbols_1,number_1] ’, ‘ filter[Keys_2 ,symbols_2,number_2]
```

> **NOTE:** Pay attention that HaSAPPy requires one filter line starting with the `@8C)` TAG for each generated table. Empty filter lines should be used for tables without filtering. The filters will be applied to the tables in the same order as the tables are listed.

```
Provide a filter parameter to select/sort values displayed (N.B. more than one filter can be defined):
Keys: as previously defined (N.B. you can not use as parameter ‘all’) 
Symbols: >, >=, < , <= , == , ascending, descending  
Number: a float or int value or nothing if (ascending/descending)
ex. :  	filter[(group2,KI,mean), >, 3.45]
filter[(group1,KI,mean), ==, 3.45],filter[(group2,Bias,mean), ascending]
@8C) filter[(Condition_A,KI,mean), >, 10]
@8C) filter[(Condition_A,KI,mean), >, 10]
@8C) filter[(Condition_A,KI,mean), >, 10], filter[(Condition_A,Score), descending]
@8C) 
…
```

If this module is the starting point of the analysis, you should provide information on the location of the GroupAnalysis to use for table generation ( `../../Analysis/yyyy-mm-dd /raw/GroupAnalysis.pkl`):

```
!!!N.B. Compile the following section just if this is your starting point!!!
Location of file storing GroupAnalysis informations:
@8D)
```

## Section 9: Design gene insertions

For candidate genes that are of interest visualization of the insertion patterns over the gene model can be graphically rendered by the **Design.py** module. This is useful for assessing if insertions have integrated in specific regions of a gene or to inspect orientation of insertions within introns. Genes for this type of analysis will have been identified from inspecting tables obtained from an earlier run of the workflow, or can be any expected candidates or positive controls of the screen. In addition, plots can be generated for the distribution of genes according to the analysed parameters. Output is provided as high quality vector graphics in SVG format, which can be further processed using common vector graphics programs (eg. Adobe Illustrator, or Inkscape) for scaling and setting font sizes for generating publishable figures.

The user can specify which type of plot is generated by entering `Y` or `N`
```
Type of graph to generate (mark ‘Y’ or ’N’):
Plot I.I. in gene models
@9A) Y
Plot Gene distribution according analysed parameter:
@9B) Y
```

If the `Plot I.I. in gene models` option is chosen, the following information is required:
```
FOR Plot I.I. in gene models:
```

1. The absolute PATH must be provided for the gene reference file created by the GeneReference_built.py module.	
```
Location of gene reference:
@9C) Users/User/HaSAPPy/docs/GeneReference_Mouse-MM10.pkl
```

2. A list of genes or chromosome intervals that you are interested. A plot contained in a separate .svg file will be generate for each of the items of the list. For including a gene name, enter the same name as the gene name appears in the gene annotation reference file or the generated tables. If you are interested to visualize insertions in a specific chromosome interval provide the following information:
```
“chromosome_startIV_endIV”.
```

A list of genes/intervals can be provided subdivided by a comma `,`. Spaces between names are accepted and trimmed by the parser in HaSAPPy.
```
Genes list to analyse (also genomic intervals can be provided):
ex: 	gene1,gene2,gene3
ex:	chrX_12345619_12456789,chr2_3726189_3726567
@9D) Xist, Trp53, chrX_12345619_12456789
```

If the `Plot Gene distribution according analysed parameters` option has been selected, the following information is required:
```
FOR Plot Gene distribution according analysed parameter:
```

If the Outlier analysis has been performed during th eworkflow, the user has the possibility to mark genes with a Outlier Score value above a threshold in a different color. Enter `Y` in the input field below to activate this feature:
```
Do you want to highlight outliers (mark ‘Y’ or ’N’):
@9E) Y
```

Provide the Score cut-off threshold value as an integer:
```
Starting Outlier score to mark as outliers genes (Fill this part just if marked ‘Y’ to the previously task):
@9F) 40
```

The plot can furthermore be annotated with the names of genes that can be specified by the user. To activate this feature enter `Y` in the input field below:
```
Do you want to annotate some gene names in the plot (mark ‘Y’ or ’N’):
@9G) Y
```

The list of gene names to be used for annotation in the plot can be specified in the following input field as a comma separated list (eg. gene1,gene2,gene3) or as a numeric value for a Score value as cut-off threshold:
```
Genes list to annotate or Outlier starting value:
ex: 	gene1,gene2,gene3
ex:	22
@9H) Xist, Trp53
```

If this module is the starting point of the analysis, you should provide absolute PATH to the database file from the GroupAnalysis ( `../../Analysis/yyyy-mm-dd /raw/GroupAnalysis.pkl`) to be used for the generation of plots:
```
!!!N.B. Compile the following section just if this is your starting point!!!
Location of file storing GroupAnalysis informations:
@9I)
```

## Final remarks

Save the completed `LoadModule.txt` file with a new name and use it as input for runnning the HaSAPPy_start.py module from the command line.

`python HaSAPPy_start.py <path-to-LoadModule.txt>`

HaSAPPy command scripts are parsed in straight a forward and simple way. The parser in the the **INFOloads.py** module searches for specific TAGs (eg. `@1A)` and reads the remainder of the line into a Python object. Only TAG lines that correspond to scheduled data processing sections of a workflow are required. All other lines are ignored by HaSAPPy and simply contain text for supporting the user for entering the correct information. This should make it possible to use a line based interface for producing command scripts in an automated or GUI supported way in the future.

[**RETURN TO THE MAIN PAGE**](https://github.com/gdiminin/HaSAPPy/blob/master/README.md)
